<!DOCTYPE html>
<html>
<head>
<title> CS391 Log </title>
<link rel="stylesheet" href="style.css">
</head>
<body>

    <ul class="nav">
        <li class="nav"><a class="active" href="index.html">Home</a></li>
        <li class="nav"><a href="log.html">Log</a></li>
    </ul>

    <h2> Work Log </h2>
    <h4> Note: 9 hours must be logged per week </h4>

    <!-- week one -->
    <div>
        <h3> Week 1</h3>
        <table>
            <tr>
              <th>3 hours</th>
              <th>1 hour</th>
              <th>5 hours</th>
            </tr>
            <tr>
              <td>Worked on log webpage + reviewed HTML + CSS skills </td>
              <td>Explored Kaggle webpage features </td>
              <td>Watched videos in Coursera (How to Win a Data Science Competition), up until week 2 </td>
            </tr>
          </table>
    </div>

    <!-- week two -->
    <div>
      <h3> Week 2</h3>
      <table>
          <tr>
            <th>2 hour</th>
            <th>3 hours</th>
            <th>4 hours</th>
          </tr>
          <tr>
            <td> Anaconda Installation plus demo </td>
            <td> Coursera - How to Win a Data Science Competition videos </td>
            <td> Coursera - How to Win a Data Science Competition videos</td>
          </tr>
        </table>
  </div>

  <!-- week four -->
    <div>
      <h3> Week 4</h3>
      <table>
          <tr>
            <th> 45 minutes </th>
            <th> 15 minutes </th>
            <th>  1 hour 30 minutes </th>
            <th>  1 hour 45 minutes </th>
          </tr>
          <tr>
            <td> Spyder Tutorial. 1. Interactive Tour. 2. First steps with Spyder: Creating hello.py and executing a program, 
              calling existing functions, inspecting and updating objects. 3. Recommended first steps for Python Begineers:
              Reset the namespace. 4. Reviewed some shortcuts for Spyder. </td>
            <td> Review Getting Started with Anaconda:Launching and closing Spyder and Jupyter Notebook. 
              Creating first Jupyter Notebook. Writing Python program using Anaconda prompt. 
              Using Anaconda Prompt to launch Spyder and Jupyter Notebook.  </td>
            <td> Watched RL Course by David Silver. <a href="https://deepmind.com/learning-resources/-introduction-reinforcement-learning-david-silver">Click Here for source.</a> - Lecture 1: Introduction to Reinforcement Learning.
              Took notes on what is RL?, what are rewards?, Agent and environements, 3 types of states, levels of observability in environements, Policy vs value functions vs model, Exploration vs Explotation,
          Prediction vs Control. </td>
          <td> RL Course by David Silver - Lecture 2: Markov Decision Process. 
            Took notes on what is Markov Process?, Markov property, Markov Reward Process, Discounts in Markov, Bellman Equation, Markov Decision Process. </td>
          </tr>
        </table>

        <table>
          <tr>
            <th>  1 hour 30 minutes </th>
            <th>  1 hour 30 minutes </th>
            <th>  1 hour 30 minutes </th>
            <th>  1 hour 30 minutes </th>
          </tr>
          <tr>
            <td> RL Course by David Silver - Lecture 3: Planning by Dynamic Programming. 
              Took notes on:  Dynamic Programming: requirements, plans, and applications. Policy Evaluation and Iteration and Improvement. Principle of Optimality </td>
            <td> RL Course by David Silver - Lecture 4: Model-Free Prediction. 
              Took notes on: Monte-Carlo Reinforcement Learning, Monte-Carlo Policy evaluation, Temporal-difference learning, comparison between Monte-Carlo and Temporal-difference, Bootstrapping and Sampling. </td>
            <td> RL Course by David Silver - Lecture 5: Model Free Control. 
              Took notes on Model-Free Control, On and off policy learning, On-policy Monte-Carlo Control, Sarsa algorithm, On-policy Temporal-Difference Learning, Off Policy learning. </td>
            <td> RL Course by David Silver - Lecture 6: Value Function Approximation. 
              Took notes on Large-Scale reinforcement learning, value function approximations, incremental methods: gradient descent, Monte-Carlo and Temporal-difference with function approximation, batch reinforcement learning. </td>
          </tr>
        </table>
  </div>
  
  <!-- week five -->
  <div>
    <h3> Week 5 </h3>
    <table>
      <tr>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 45 minutes </th>
        <th>  30 minutes </th>
        <th>  30 minutes </th>
      </tr>
      <tr>
        <td> RL Course by David Silver - Lecture 7: Policy Gradient Methods. Took notes on Value-Based and Policy-Based Reinforcement Learning. Pros and Cons of Policy-Based RL. Monte-Carlo Policy and Actor-Critic Policy Gradient. </td>
        <td> RL Course by David Silver - Lecture 8: Integrating Learning and Planning. Took notes on Model-Based Reinforcement Learning. What is a Model? Model Learning. Integerated Architectures: Dyna Architecture. Simulation-Based Search: in Monte-Carlo and Temporal-difference. </td>
        <td> Looked online for resources regarding the game snake to use as a basis for the Hungry Geese Kaggle competition.<a href="https://becominghuman.ai/designing-ai-solving-snake-with-evolution-f3dd6a9da867"> This resource </a> talked about Neural Networks and using evolution to train logic into our agent. The approach this person used is by providing random mutations to the agent so it would evolve that logic to play the snake game. </td>
        <td> Took time to read into other resources that classmates posted to shared document. Learned about a couple ways to incorporate a strategies that have already been made for the snake game into the hungry geese game. Many involved neural networks and having the agent learn from simulated experiences to gain reward. I think after reading these articles, I want to further my knowledge with Neural Networks and I see we have some sources in our common doc. </td>
      </tr>
    </table>

    <table>
      <tr>
        <th>  1 hour 45 minutes </th>
        <th> 2 hours </th>
        <th> 30 minutes </th>
        <th> 1 hour and 15 minutes </th>
        <th> 1 hour 30 minutes </th>
      </tr>

      <tr>
        <td> RL Course by David Silver - Lecture 9: Exploration and Exploitation. Took notes on Exploration vs Exploitation. Multi-Armed Bandit. Bayesain Bandits.  </td>
        <td> RL Course by David Silver - Lecture 10: Classic Games. Took notes on analysis on Classic Games: Checkers, Chess, Scarbble, etc. Perfect and Imperfect Information Games. Binary-Linear Value Function in Checkers and weighing the value of each piece. Self-play Reinforcement Learning.  </td>
        <td> Played around with the <a href= "https://bit.ly/3ccpuoS">Neural Network Playgound </a> Demo that was in the shared class document. I am still confused with how neural networks work. I see that they function like humn brains that have neurons and fluctuate their adaptability given different environments. I tried playing with finding a smaller test lost. My next step is to watch about Neural Networks and Deep Learning in coursera.  </td>
        <td> Began to watch <a href="https://www.coursera.org/learn/neural-networks-deep-learning"> Coursera </a> videos about Neural Networks and Deep Learning. I watched the first week worth of videos which introduces what the course will cover. At this point I have learned what Neural Networks are and supervised learning in them. They also touch bases on why deep learning is popular right now and its applications. </td>
        <td> Watched about half of the content for Week 2 Neural Networks and Deep Learning Coursera course. Some of the topics covered were Binary Classification, Logistic Regression, Gradient Descent, Derivatives, and Vectorization. After watching these videos I was confused and I think my next steps for next week will be to take a step back and do more application practice of basic manipulation with sets of data. I plan on going to office hours to make a plan of how to come up with my own assignments. </td>
      </tr>
    </table>
  </div>

  <!-- week six -->
  <div>
    <h3> Week 6 </h3>
    <table>
      <tr>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour </th>
        <th>  1 hour 30 minutes </th>
      </tr>
      <tr>
        <td> I looked up a follow along course on youtube to begin to pratice Python. I had previously in week 4, began to do a couple tutorials to become familiar with the Jupyter Notebooks environment. The course video can be found <a href="https://bit.ly/3sWqcgI"> here. </a> During this session I got familiarity with problem solving in Python, which has a similar format to Python. I also learned about a couple IDEs other than Jupyter Notebooks for Python. </td>
        <td> During this session I continued the course video I follow along last session. So far it is more basic review on simple declaring variables, using operations, calling %whos to get all variables that are in the workspace and getting their variable type. Pretty simple concepts that are easy to grasp because I now have experience in another language. I plan on looking for a higher level video to follow along per se more applied on data science application. </td>
        <td> Watched a very interesting <a href="https://www.youtube.com/watch?v=WXuK6gekU1Y"> documentary</a> about the game GO. This game is very popular in South Korea where they train people from a young age. The professor from the Reinforcement Learning course videos that I watched was one of the main managers in a team. This team using neural networks to develop an artificial player that would optimally find a pattern to beat any human player. The team developed their agent and had it compete against a local best player of GO in a part of Europe. Their agent is called AlphaGo. AlphaGo was able to beat this human player. Then Alpha go went up again a man who is among the top 7 world players of the game Go. With a result of 4-1, AlphGo wins. It was interesting how so many people were broadcasting these plays. Another point in their development of AlphaGo, after going against their local opponent, they had the man play several rounds with AlphaGo to find a weakness before it went against one of the worlds best players. </td>
      </tr>
    </table>

    <table>
      <tr>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
      </tr>
      <tr>
        <td> I began to look into some of the notebooks provided for hungry geese <a href="https://www.kaggle.com/ihelon/hungry-geese-agents-comparison"> specifically the one for agent comparison. </a> Ricky had sugguested this resources to begin a set up environment for Hunrgy Geese during our breakout room. </td>
        <td> Picked up again on watching <a href="https://www.coursera.org/learn/neural-networks-deep-learning"> Coursera </a> videos about Neural Networks and Deep Learning. I stoped at about a quarter of week 3 material. Some topics that were covered were more examples of vectorization, broadcasting Python and Jupyter Notebooks (which was more of a recap), representing Neural Networks and what computing their outputs looks like.   </td>
        <td> Continued the Neural Networks and Deep Learning Coursera, wrapped up week 3 topics. Some of the topics that were highlighted were more Vectorization examples, activation function which calculate and determine the output of neural networks, derivatives of activation functions. </td>
        <td> I followed along with a <a href="https://www.kaggle.com/rutailiu/titanic-ml-project">journal</a> from a team for the Titanic Kaggle Competition. I needed some example of importing data and manipulating it, analyzing it, and manipulating it. </td>
      </tr>
    </table>
  </div>

  <!-- week seven -->
  <div>
    <h3> Week 7 </h3>
    <table>
      <tr>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
      </tr>
      <tr>
        <td> My intent during this seating was to set an environement of Pyhton and Juptyer Notebook in VSCode, but after a while I decided that I would just use the environments I have. I could not get a Python terminal, like Ricky had mentioned that we should have, instead I had a powershell console. I also browsed through the DS256 course page and material. I set a space on my laptop to install the DS Jupyter Notebooks. I plan on doing some of those assignments in the future to begin to learn the applied coding aspect in DS to prepare for the Exam. </td>
        <td> After looking at some of the coding implementation for more DS focused, I reevaluated my confidence with Python. In a previous week I followed along with a begineers Youtube video to Python and because I began with variable declarations, assignment, and basic operators, it seemed easy to me. However, during this session I went back to Python learning. This time around I followed the <i>Whirlwind Tour of Python</i> by Jake VanderPlas. I started with Basic Python Semantics: Operators. Although I had reviewed operators before, I went to the end of the section to look at <i>Identity and Membership Operators</i> because I have never heard of that before. I ended at <i>Built-In Types: Simple Values</i> which was about variable types. Something I found interesting is how Python has the type "NoneType" that indicates null, meanwhile, I belive in Java you just store null in any data type straight forward. </td>
      </tr>
    </table>

    <table>
      <tr>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
      </tr>
      <tr>
        <td> During this session I continued <i>Whirlwind Tour of Python</i> by Jake VanderPlas. I started with the <i>Built-In Data Structures.</i> I don't know how much I will need apply data structures in the coding for the DS competitions. However, it was nice to review some concepts since I took the course last year. The data structures covered were list, tuple, dict(hashmaps), and set. This included declaring, using pertaining methods, and accessing values. I ended on <i>Control Flow</i> which covered condition statements and loops. I decided to review this seccion because although I know how loops and condition statements work, I wanted to understand the syntax of these funtions. </td>
        <td> This session was a continuation of <i>Whirlwind Tour of Python</i> by Jake VanderPlas. This time I reviewed <i>Defining and Using Functions.</i> Again this was a quick review to look for syntax in Pyhton just like I did for conditional statements and for loops in my last session. This section also covered Flexible Arguements and Anonymous Functions, which was new to me. Then I ended in <i>Errors and Excpetions.</i> This was a review of different types of errors and writing code to catch those exceptions. Also the command raise was covered, which reminds me of when we use print statements to debug in Java.</td>
      </tr>
    </table>

    <table>
      <tr>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
      </tr>
      <tr>
        <td> Continued <i>Whirlwind Tour of Python</i> by Jake VanderPlas in during this session. I began with <i>Iterators</i>. This section simply covered implementing a range and a for-each in loops. Enumurate to keep track of the index. Zip which syncs two iterables when you want to iterate multple lists at the same time. Map which combines an iterator and function over a list. Filter is the same as Map, but it only shows values that are true for the function. </td>
        <td> During this section I started with <i>List Comprehension</i> in <i>Whirlwind Tour of Python</i> by Jake VanderPlas. This section is rewriting loops in a format that would match the English more. I ended at <i>Generators</i>, which is still confusing to me. I understood that it is similar to List Comprehension. The book described it as a recipe for producing values, however, I still do not understand the difference between these two concepts. </td>
        <td> I continued <i>Whirlwind Tour of Python</i> by Jake VanderPlas, starting with <i>Modules and Packages.</i> This had to do with importing modules and this also includes third-party modules. This makes sense how we can import modules from lets say Kaggle and make working with data science. I also went over <i>String Manipulation and Regular Expressions.</i> This section was very lengthy and was nice to go over string specific methods in Python, so it was straightforward. Next week I hope to begin chapter 5 from <i>Python Data Science Handbook</i> by Jake VanderPlas. I want to focus on chapter 5 because it is about machine learning and basic In-Depth algorithms that I could potentially use for the exam. </td>
      </tr>
    </table>
  </div>

   <!-- week eight -->
   <div>
    <h3> Week 8 </h3>
    <table>
      <tr>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
      </tr>
      <tr>
        <td> During this session I followed along the Preview of Data Science Tools section from <i>Whirlwind Tour of Python</i> by Jake VanderPlas. This was an introduction to some of the packages and basic commands possible in those packages. I followed along with the textbook by making my own problems in a Jupyter Notebook. The packages covered were Numpy which allows us to have multi-dimensional arrays. Pandas which builds off of Numpy and allows to apply labels to the arrays. Matplotlib is a visualization package to see plots. SciPy is more of a numerical computing package. This was nice to have to ease into the next Jake VanderPlas Python book. </td>
        <td> I began the <i>Python Data Science Handbook</i> by Jake VanderPlas. I started at the IPython: Beyind Normal Python. In this section I was able to follow along with <i>Help and Documentation in Python</i> through <i>Input and Output History</i> in my own separate Jupyter Notebook. These sections were introduction to using functions and shortcuts in IPython. I decided to use the Jupyter Notebooks in a URL instead of the command line. Although this was somewhat of a review I decided to take your input and begin from the start. This way I can build up to chapter 5, which will help me out with the exam.  </td>
        <td> This session I completed the other half of the <i>IPython: Beyond Normal Python</i> section in the <i>Python Data Science Handbook</i> by Jake VanderPlas. I started at <i>IPython and Shell Commands</i> and ended at <i>More IPython Resources.</i> This section covered shell commands which were commands we learned in cs111. How to debug in my code using the %xmode command, which had three possibilities. I liked how the plain option gives you a condense version of your error because it can be tough to depict what the error is. I also learned about commands to time code snippets. </td>
      </tr>
    </table>

    <table>
      <tr>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
      </tr>
      <tr>
        <td> During this session I started the <i>Introduction to NumPy</i> in the <i>Python Data Science Handbook</i> by Jake VanderPlas. I got through <i>Understanding Data Types in Python</i> up to <i>Computation on NumPy Arrays: Universal Functions.</i> I learned more about data types in NumPy, specifically Integers and the many functions to Arrays. Arrays seems to be an ongoing important data structure within data science. I also learned about ufuncs which are used to execute repeated operations much more quickly than loops. </td>
        <td> I continued the <i>Introduction to NumPy</i> in the <i>Python Data Science Handbook</i> by Jake VanderPlas. I followed along in my own Jupyter Notebook, starting at <i>Aggregations:Min, Max, and Everything in Between</i> to <i>Comparisons, Masks, and Boolean Logic.</i> Some things I learned were basic operations like summing values in an array, finding the min and max. It is important to know how to do these basic operations to manipulate the data sets. Broadcasting was also brough up where operations can be performed on all values no matter what the array dimensions are. One example was adding a scalar to the array. In the last section that I followed along, they talked about comparison operators and working with boolean operators and arrays.</td>
        <td> I finished the the <i>Introduction to NumPy</i> in the <i>Python Data Science Handbook</i> by Jake VanderPlas section. During this session I learned about exploring fancy indexing, which means to pass an array of indices to access various elements at the same time. It also talked about sorting data in arrays, which it brought up algorithms that we have seen in 216. The last part was about structured arrays which are arrays with compound data types to indicate that there is a relationship between them. We could separate the data into different arrays based on data type, but we wouldn't know if they relate at all. </td>
      </tr>
    </table>
  </div>

  <!-- week nine
  <i>Python Data Science Handbook</i> by Jake VanderPlas textbook -->
  <div>
    <h3> Week 9 </h3>
    <table>
      <tr>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
      </tr>
      <tr>
        <td> This week I intend on going through chapter 3 (Pandas) of <i>Python Data Science Handbook</i> by Jake VanderPlas textbook. During this session I got through <i>Introducing Pandas Objects</i> and finished at <i>Operating on Data in Pandas.</i> Pandas are a built off of NumPy to enhance the data structures and understand them mor thoroughly. I followed along on my own on my Jupyter Notebook. The Pandas introduction seems very similar to NumPy so far, with just an introduction of some new functions.</td>
        <td> I picked up on chapter 3 of the <i>Python Data Science Handbook</i> by Jake VanderPlas textbook. I started at <i>Handling Missing Data</i> and ended at <i>Combining Datasets: Concat and Append.</i> It was interesting to read bout missing data. It was stated that in real life sometimes we don't have a clean cut  set of data. Therefore, in Pandas, there are multiple ways to indicate these missing data bits here and there. I wonder if when using agents, eventually, these missing data bits get filled up by some value because the agents are making estimations based on future states and environments. Another neat take away was MultiIndex in Pandas. It's very neat how we can organize and priotitize more certain values in arrays. </td>
        <td> I continued with the Jake VanderPlas, and I will state now that my entire week of work is intended to be from the Python Data Science textbook. So I picked up on <i>Combining Datasets: Merge and Join</i> and followed along and worked through <i>Pivot Tables.</i> During this section it was nice to know that it is Pandas allows an easy way to merge data. There are also many ways to megre data: one-to-one, many-to-one, and many-to-many. There are also many ways to specific how to nicely line the data by columns. Overall, these sections had to do with grouping data in various manners. </td>
      </tr>
    </table>

    <table>
      <tr>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
        <th>  1 hour 30 minutes </th>
      </tr>
      <tr>
        <td> I covered sections <i>Vectorized String Operations</i> to <i>High-Performance Pandas: eval() and query()</i> in chapter 3. One great thing about Panda is vectorization of operations, which makes manipulating arrays so much easier, without having to worry about size. I also learned about times and datas in Panda and how it is useful that there are many functions to easily organize tables of data with dates. This section was a little tougher to understand only because there was a lot of information that was thrown as a reader. It is kind of overwhelming learning all of these functions. </td>
        <td> During this session, I started chapter 4, <i>Visualization with Matplotlib.</i> I got through the introduction of this chapter and ended at <i>Density and Contour Plots.</i> So Matplotlib is a visualization library for data. There was not much that stuck out to me. It reminded me of my mathematica labs that I've done for multivariable so far. Using commands to show graphs and visualization of trends. </td>
        <td> I continued with chapter 4 of <i>Python Data Science Handbook</i> by Jake VanderPlas. I started at <i>Histograms, Binnings, and Density</i> and finsihed at <i>Multiple Subplots.</i> I felt again during this session that there wasn't anything too crazy presented. I definitely think is it important to have these tools to visualize, but again it reminded me of my mathematica lab to an extent. I think I may just skip to the start of chapter 5 next week to finally start to implement some sort of basic data technique implementation into my exam because I know chapter 5 introduces them. </td>
      </tr>
    </table>
  </div>

</body>
</html>